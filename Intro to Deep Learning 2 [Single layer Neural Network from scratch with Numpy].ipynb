{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Neural Network is an algorithm that learns to identify patterns in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backpropagation is a technique to train Neural Networks to update weights by minimising error value through Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Learning = Many Layer Neural Net + Large amount of Data + Heavy Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from basic_neural_net import NeuralNetwork\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read data\n",
    "train = pd.read_csv('titanic/train.csv',header=0)\n",
    "test = pd.read_csv('titanic/test.csv',header=0)\n",
    "minmax = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train.head()\n",
    "\n",
    "#test.head()\n",
    "\n",
    "#train.shape\n",
    "\n",
    "#test.shape\n",
    "\n",
    "#basic preprocessing\n",
    "\n",
    "#sum(test.Sex.isnull())   #number of blank values in Sex\n",
    "\n",
    "#sum(test.Embarked.isnull())  #number of blank values in Embarked   #remove 2 rows\n",
    "\n",
    "#sum(test.Age.isnull())  #impute\n",
    "\n",
    "#sum(test.Pclass.isnull())\n",
    "\n",
    "#sum(test.SibSp.isnull())\n",
    "\n",
    "#sum(test.Parch.isnull())\n",
    "\n",
    "#sum(test.Cabin.isnull())  #delete this column\n",
    "\n",
    "#sum(test.Fare.isnull())\n",
    "\n",
    "#np.mean(test.Fare[test.Fare.notnull()].values)\n",
    "\n",
    "#delete 'PassengerId','Name','Cabin' and 'Ticket'\n",
    "#delete 2 blank 'Embarked' rows\n",
    "#One hot 'Sex' and 'Embarked'\n",
    "#delete 'Cabin'\n",
    "#impute 177 rows of Age with some values or remove the column #say for now we impute it with the median of the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def age_imputation(data,a,p,m):\n",
    "    data1 = data[data.Age>a]\n",
    "    data1 = data1[data1.Pclass==p]\n",
    "    data1 = data1[data1.male==m]\n",
    "    return np.mean(data1.Age.values)\n",
    "\n",
    "def preprocessing(data):\n",
    "    data.drop_duplicates(inplace=True)\n",
    "    data.drop(['Ticket','Cabin'],axis=1,inplace=True)\n",
    "    data = data[data.Embarked.notnull()]\n",
    "    male = []\n",
    "    female = []\n",
    "    for i in data.Sex.values:\n",
    "        if i == 'female':\n",
    "            male.append(0)\n",
    "            female.append(1)\n",
    "        else:\n",
    "            male.append(1)\n",
    "            female.append(0)\n",
    "    data['female'] = female\n",
    "    data['male'] = male\n",
    "    embarked_C = []\n",
    "    embarked_Q = []\n",
    "    embarked_S = []\n",
    "    for i in data.Embarked.values:\n",
    "        if i == 'C':\n",
    "            embarked_C.append(1)\n",
    "            embarked_Q.append(0)\n",
    "            embarked_S.append(0)\n",
    "        elif i == 'Q':\n",
    "            embarked_C.append(0)\n",
    "            embarked_Q.append(1)\n",
    "            embarked_S.append(0)\n",
    "        else:\n",
    "            embarked_C.append(0)\n",
    "            embarked_Q.append(0)\n",
    "            embarked_S.append(1)\n",
    "    data['embarked_c'] = embarked_C\n",
    "    data['embarked_q'] = embarked_Q\n",
    "    data['embarked_s'] = embarked_S\n",
    "    data.Age.fillna(-1.0,inplace=True)\n",
    "    data.Fare.fillna(np.mean(data.Fare[data.Fare.notnull()].values))\n",
    "    age = []\n",
    "    for i in range(data.shape[0]):\n",
    "        if data.Age.values[i] != -1:\n",
    "            age.append(data.Age.values[i])\n",
    "        elif data.Age.values[i] == -1 and data.Pclass.values[i] == 1:\n",
    "            if data.male.values[i] == 0:\n",
    "                age.append(age_imputation(data,0,1,0))\n",
    "            else:\n",
    "                age.append(age_imputation(data,0,1,1))\n",
    "        elif data.Age.values[i] == -1 and data.Pclass.values[i] == 2:\n",
    "            if data.male.values[i] == 0:\n",
    "                age.append(age_imputation(data,0,2,0))\n",
    "            else:\n",
    "                age.append(age_imputation(data,0,2,1))       \n",
    "        elif data.Age.values[i] == -1 and data.Pclass.values[i] == 3:\n",
    "            if data.male.values[i] == 0:\n",
    "                age.append(age_imputation(data,0,3,0))\n",
    "            else:\n",
    "                age.append(age_imputation(data,0,3,1))   \n",
    "    pclass_1 = []\n",
    "    pclass_2 = []\n",
    "    pclass_3 = []\n",
    "    for i in data.Pclass.values:\n",
    "        if i == 1:\n",
    "            pclass_1.append(1)\n",
    "            pclass_2.append(0)\n",
    "            pclass_3.append(0)\n",
    "        elif i == 2:\n",
    "            pclass_1.append(0)\n",
    "            pclass_2.append(1)\n",
    "            pclass_3.append(0)\n",
    "        else:\n",
    "            pclass_1.append(0)\n",
    "            pclass_2.append(0)\n",
    "            pclass_3.append(1)\n",
    "    data['pclass_1'] = pclass_1\n",
    "    data['pclass_2'] = pclass_2\n",
    "    data['pclass_3'] = pclass_3\n",
    "    data.drop(['Pclass','Sex','Embarked'],axis=1,inplace=True)\n",
    "    data['Age'] = age\n",
    "    data['family_size'] = data.SibSp + data.Parch + 1\n",
    "    data.Fare.fillna(-1.0,inplace=True)\n",
    "    fare = []\n",
    "    data_pclass_1 = data[data.pclass_1==1]\n",
    "    data_pclass_2 = data[data.pclass_2==1]\n",
    "    data_pclass_3 = data[data.pclass_3==1]\n",
    "    fare_class_1 = data_pclass_1.Fare.values\n",
    "    fare_class_2 = data_pclass_2.Fare.values\n",
    "    fare_class_3 = data_pclass_3.Fare.values\n",
    "    fare_mean_class1 = np.mean(fare_class_1)\n",
    "    fare_mean_class2 = np.mean(fare_class_2)\n",
    "    fare_mean_class3 = np.mean(fare_class_3)\n",
    "    for i in range(data.shape[0]):\n",
    "        if data.Fare.values[i] == -1 and data.pclass_1.values[i] == 1:\n",
    "            fare.append(fare_mean_class1)\n",
    "        elif data.Fare.values[i] == -1 and data.pclass_2.values[i] == 1:\n",
    "            fare.append(fare_mean_class2)\n",
    "        elif data.Fare.values[i] == -1 and data.pclass_3.values[i] == 1:\n",
    "            fare.append(fare_mean_class3)\n",
    "        else:\n",
    "            fare.append(data.Fare.values[i])\n",
    "    data.Fare = fare\n",
    "    data.Fare = minmax.fit_transform(data.Fare)\n",
    "    data.Age = minmax.fit_transform(data.Age)\n",
    "    title = []\n",
    "    for b in data.Name.values:\n",
    "        title.append(b[(b.find(', ')+2):b.find('.')])\n",
    "    data.Name = title\n",
    "    mr = []\n",
    "    mrs = []\n",
    "    miss = []\n",
    "    master = []\n",
    "    mean_miss = np.mean(data[data.Name == 'Miss'].Age.values)\n",
    "    mean_master = np.mean(data[data.Name == 'Master'].Age.values)\n",
    "    for i in range(data.shape[0]):\n",
    "        if title[i] in ['Capt', 'Col', 'Don', 'Dr', 'Jonkheer', 'Major','Mlle','Mme']:\n",
    "            if data.male.values[i] == 0 and data.Age.values[i] <= mean_miss:\n",
    "                miss.append(1)\n",
    "                mr.append(0)\n",
    "                mrs.append(0)\n",
    "                master.append(0)\n",
    "            elif data.male.values[i] == 0 and data.Age.values[i] > mean_miss:\n",
    "                miss.append(0)\n",
    "                mr.append(0)\n",
    "                mrs.append(1)\n",
    "                master.append(0)\n",
    "            elif data.male.values[i] == 1 and data.Age.values[i] > mean_master:\n",
    "                miss.append(0)\n",
    "                mr.append(1)\n",
    "                mrs.append(0)\n",
    "                master.append(0)\n",
    "            elif data.male.values[i] == 1 and data.Age.values[i] <= mean_master:\n",
    "                miss.append(0)\n",
    "                mr.append(0)\n",
    "                mrs.append(0)\n",
    "                master.append(1)\n",
    "        elif title[i] in ['Lady','Mrs','the Countess']:\n",
    "                miss.append(0)\n",
    "                mr.append(0)\n",
    "                mrs.append(1)\n",
    "                master.append(0)\n",
    "        elif title[i] == 'Master':\n",
    "                miss.append(0)\n",
    "                mr.append(0)\n",
    "                mrs.append(0)\n",
    "                master.append(1)\n",
    "        elif title[i] in ['Miss','Ms']:\n",
    "                miss.append(1)\n",
    "                mr.append(0)\n",
    "                mrs.append(0)\n",
    "                master.append(0)\n",
    "        else:\n",
    "                miss.append(0)\n",
    "                mr.append(1)\n",
    "                mrs.append(0)\n",
    "                master.append(0)\n",
    "    data['miss'] = miss\n",
    "    data['mr'] = mr\n",
    "    data['mrs'] = mrs\n",
    "    data['master'] = master\n",
    "    data.drop('Name',axis=1,inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/dist-packages/pandas/core/generic.py:3191: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:79: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:80: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:81: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:82: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:83: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/dist-packages/pandas/core/generic.py:2701: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:324: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:359: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:324: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:359: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:161: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:162: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:163: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#train_processed = preprocessing(train)\n",
    "#test_processed = preprocessing(test)\n",
    "pid_train = train.PassengerId.values\n",
    "pid_test = test.PassengerId.values\n",
    "total_Data = pd.DataFrame()\n",
    "total_Data = total_Data.append(train)\n",
    "total_Data = total_Data.append(test)\n",
    "total_Data_processed = preprocessing(total_Data)\n",
    "total_Data_processed = total_Data_processed[['Survived','Age', 'Fare', 'Parch', 'PassengerId', 'SibSp',\n",
    "       'female', 'male', 'embarked_c', 'embarked_q', 'embarked_s',\n",
    "       'pclass_1', 'pclass_2', 'pclass_3', 'family_size', 'miss', 'mr',\n",
    "       'mrs', 'master']]\n",
    "train = total_Data_processed[total_Data_processed.PassengerId.isin(pid_train)]\n",
    "train.drop('PassengerId',axis=1,inplace=True)\n",
    "test = total_Data_processed[total_Data_processed.PassengerId.isin(pid_test)]\n",
    "test.drop('PassengerId',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_id = np.random.choice(range(train.shape[0]), 150, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_id = list(set(range(train.shape[0])) - set(list(val_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validation_set = train.iloc[val_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_processed_final = train.iloc[train_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = train_processed_final.iloc[:,1:].values\n",
    "x_valid = validation_set.iloc[:,1:].values\n",
    "x_test = test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train = train_processed_final.iloc[:,0]\n",
    "y_valid = validation_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iters = 10000\n",
    "learning_rate = 0.000001\n",
    "nn.train(x=x_train,y=y_train,iterations=iters,learning_rate=learning_rate,batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = nn.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.565629228687413"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.accuracy(y_pred,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.666666666666664"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_pred = nn.predict(x_valid)\n",
    "nn.accuracy(valid_pred,y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(criterion='entropy',min_samples_leaf=1,min_samples_split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(X=x_train,y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96752368064952643"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.score(X=x_train,y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78000000000000003"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.score(X=x_valid,y=y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xtf = tf.placeholder(tf.float32,[None,x_train.shape[1]])\n",
    "ytf = tf.placeholder(tf.float32,[None,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = tf.Variable(tf.zeros([x_train.shape[1],1]))\n",
    "b = tf.Variable(tf.zeros([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logit = tf.add(tf.matmul(xtf,w),b)\n",
    "activation = tf.nn.softmax(logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.reduce_sum(tf.square(ytf-activation),reduction_indices=[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.000001).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(ax,ay):\n",
    "    ypred = sess.run(activation,feed_dict={xtf:ax})\n",
    "    acty = sess.run(ytf,feed_dict={ytf:ay})\n",
    "    ypredn = []\n",
    "    for i in ypred:\n",
    "        if i<0.5:\n",
    "            ypredn.append(1)\n",
    "        else:\n",
    "            ypredn.append(0)\n",
    "    ypredn = np.asarray(ypredn)\n",
    "    return np.mean(np.equal(ypredn,acty))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-30-80f4a80570a7>:1: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost : 0.635, accuracy train : 61.434, accuracy valid : 63.333\n",
      "cost : 0.665, accuracy train : 61.434, accuracy valid : 63.333\n",
      "cost : 0.620, accuracy train : 61.434, accuracy valid : 63.333\n",
      "cost : 0.610, accuracy train : 61.434, accuracy valid : 63.333\n",
      "cost : 0.605, accuracy train : 61.434, accuracy valid : 63.333\n",
      "cost : 0.625, accuracy train : 61.434, accuracy valid : 63.333\n",
      "cost : 0.640, accuracy train : 61.434, accuracy valid : 63.333\n",
      "cost : 0.625, accuracy train : 61.434, accuracy valid : 63.333\n",
      "cost : 0.620, accuracy train : 61.434, accuracy valid : 63.333\n",
      "cost : 0.595, accuracy train : 61.434, accuracy valid : 63.333\n"
     ]
    }
   ],
   "source": [
    "y_train = y_train.reshape([y_train.shape[0],1])\n",
    "y_valid = y_valid.reshape([y_valid.shape[0],1])\n",
    "for i in range(10000):\n",
    "    batch_ids = np.random.choice(range(train_processed_final.shape[0]), 200, replace=False)\n",
    "    train_batch_final = train_processed_final.iloc[batch_ids]\n",
    "    x_batch = train_batch_final.iloc[:,1:].values\n",
    "    y_batch = train_batch_final.iloc[:,0]\n",
    "    y_batch = y_batch.reshape([y_batch.shape[0],1])\n",
    "    sess.run(optimizer,feed_dict={xtf:x_batch,ytf:y_batch})\n",
    "    if i%1000 == 0:\n",
    "        c = sess.run(cost,feed_dict={xtf:x_batch,ytf:y_batch})\n",
    "        at = accuracy(x_train,y_train)\n",
    "        av = accuracy(x_valid,y_valid)\n",
    "        print \"cost : %0.3f, accuracy train : %0.3f, accuracy valid : %0.3f\"%(c,at,av)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
